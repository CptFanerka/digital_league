# Тестовое задание для компании Лига Цифровой Экономики 
> Задача:<br />
> Вам предоставляется OpenAPI спецификация для эндпоинтов системы статистики и аналитики данных о работе рекламной сети. Ваша задача - создать Docker Compose конфигурацию и связанные сервисы для развертывания этих эндпоинтов.<br />
>
> Формат решения:<br />
> Ваше решение должно предоставлять docker compose файл и все необходимые артефакты. Напишите инструкцию по развертыванию и запуску. Выложите ваше решение на GitHub или GitLab в открытый репозиторий.<br />
>
> Быстрый отклик и эффективная обработка данных:<br />
> Разработанное вами решение должно обеспечить быстрый отклик и эффективную обработку больших объемов данных.<br />
>
> Документация:<br />
> Помимо инструкции по развертыванию и запуску предоставьте краткую документацию к вашему решению (в репозитории). Если у вас есть дополнительные идеи или рекомендации по оптимизации системы или улучшению производительности, внесите их в документацию.<br />
# Установка и запуск
```
git clone https://github.com/cptfanerka/digital_league.git
cd digital_league
docker compose build
docker compose up -d
```
Работоспособность можно проверить по адресу http://localhost:8000/docs
# Документация к решению
1. Согласно OpenAPI спецификации, были созданы два FastAPI эндпоинта. В ходе разработки использовались возможности Pydantic для проверки типов данных и валидации.<br />
2. Решение упаковано в Docker Compose.<br />
3. Структура проекта создана с учетом удобства его дальнейшего развития.<br />
# Комментарии
Задание содержит требование к системе в виде быстрого отклика и эффективной обработки больших объемов данных. В рамках тестового задания я не стала добавлять сервис, который мог бы продемонстрировать выполнение этого требования, но вот что я предприняла бы, будь у меня база данных с большим количеством данных:<br />
1. Оптимизировала бы код для уменьшения сложности алгоритмов.<br />
2. Использовала бы асинхронный код и асинхронные запросы FastAPI.<br />
3. Создавала бы индексы в базе данных для ускорения запросов.<br />
4. Оптимизировала бы медленные запросы к базе.<br />
5. Использовала бы кэширование для часто запрашиваемых данных.<br />

Я перечислила общие идеи, которыми я могла бы воспользоваться, но в целом решение подобной задачи зависит от конкретной ситуации и проблемы.
